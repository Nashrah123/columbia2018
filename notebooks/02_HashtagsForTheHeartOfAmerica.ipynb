{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=http://www.trbimg.com/img-5a650443/turbine/la-1516569664-ogcunqhui7-snap-image/1200/1200x675 width=500>\n",
    "\n",
    "Who's to blame for the shutdown? Twitter's answer\n",
    "-----------------------------------------------\n",
    "\n",
    "Almost as soon as it became likely that the government was going to shutdown, hashtags started appearing on Twitter to assign blame. Evidently, the hashtag that sticks is now a barometer of public opinion. So today, we will use Twitter data as a pretext to reinforce our drill and maybe surface some questions about the material you completed for today. We will also introduce a new kind of built-in object (our last for a while) called a *dictionary*.\n",
    "\n",
    "But first, the dueling hashtags. A little has been written about the tussle between #trumpshutdown and #schumershutdown. There are, of course, other hashtags like #GOPShutdown and #NoDACANoDeal on the left, and #DoTheRightThing, #ReleaseTheMemo and #NoDACA on the right. But for now we'll consider just the main two. \n",
    "\n",
    "<img src=https://static1.squarespace.com/static/5a611e40b07869cf5b253abd/t/5a6288ce24a694f25605f054/1516370960751/180118_BUD_shutdown_web_background.png?format=1500w width=500>\n",
    "\n",
    "In the battle for public opinion the Huffington Post quotes a research group's findings that a number of pro-Russian accounts are promoting #schumershutdown. Here's a piece of their story.\n",
    "\n",
    "> [The #SchumerShutdown Hashtag Is Getting A Big Boost From Russian Bots](https://www.huffingtonpost.com/entry/government-shutdown-russia-twitter-trump_us_5a654795e4b0dc592a0a06c8)\n",
    "\n",
    ">  As lawmakers wage a messaging war over who caused the government shutdown, Republicans and the White House are getting a big boost in their efforts to blame Democrats for the mess ― from the Russians.\n",
    "\n",
    "> #SchumerShutdown ― the hashtag that GOP leaders and the White House are using to accuse Democrats of causing the shutdown ― on Sunday night became the top trending hashtag being promoted by Russian bots and trolls on Twitter, according to the Alliance for Securing Democracy, a project led by former top national security officials from both parties.\n",
    "\n",
    "> Here’s a chart by Alliance for Securing Democracy, last updated at 10 p.m. Sunday, showing the #SchumerShutdown hashtag blowing up among Russia-linked influence networks. \n",
    "\n",
    "> <img src=https://img.huffingtonpost.com/asset/5a6551601c00002700355c1e.png?ops=scalefit_720_noupscale width=400>\n",
    "\n",
    "The site quoted in the article, [\"Hamilton 68: Tracking Russian Influence Operations on Twitter\"](http://dashboard.securingdemocracy.org/), uses a particular methodology for assessing the impact of Russian influence. Have a quick read and tell us what they do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Put your answer here*\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Along with hashtags, we see that this site also aggregates mentions of important stories that are being mentioned in \"Russian influence circles.\" The top trending article when this notebook was written was an [OpEd in The Hill](http://thehill.com/opinion/white-house/369961-schumers-shutdown-reveals-democrats-will-destroy-america-just-to-spite). \n",
    "\n",
    "In addition to the Huffington Post article, there is another on [Quartz that might be worth a read, \"Russian Twitterbots are blaming the US shutdown on Democrats.\"](https://qz.com/1185452/government-shutdown-russian-bots-are-helping-republicans-blame-democrats-with-schumershutdown/) With the skills in this class, we can start to ask questions for ourselves. Are there bots involved? What evidence can we find and how do we validate the work of others?\n",
    "\n",
    "Finally, the idea of trending and a political battle over hashtags even managed to surface on places like SNL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('1O1S0RGfJ2E')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Something new - A dictionary**\n",
    "\n",
    "Download the \"quiet.json\" and the \"mach.json\" files from [the data folder of our Github repository](https://github.com/computationaljournalism/columbia2018/tree/master/data). Place these in the same folder as this notebook. These two files each represent a single tweet. They were posted around midnight just as the government shutdown took effect. Here is someone less sympathetic to the GOP, Mach229..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\"><a href=\"https://twitter.com/hashtag/TrumpShutdown?src=hash&amp;ref_src=twsrc%5Etfw\">#TrumpShutdown</a> keeps disappearing as a trend and it&#39;s not because trump has gotten better as negotiating. <a href=\"https://twitter.com/hashtag/TrumpShutdown?src=hash&amp;ref_src=twsrc%5Etfw\">#TrumpShutdown</a> <a href=\"https://twitter.com/hashtag/GOPShutdown?src=hash&amp;ref_src=twsrc%5Etfw\">#GOPShutdown</a> <a href=\"https://twitter.com/hashtag/TrumpShutdown?src=hash&amp;ref_src=twsrc%5Etfw\">#TrumpShutdown</a> <a href=\"https://twitter.com/hashtag/TrumpShutdown?src=hash&amp;ref_src=twsrc%5Etfw\">#TrumpShutdown</a> <a href=\"https://twitter.com/hashtag/TrumpShutdown?src=hash&amp;ref_src=twsrc%5Etfw\">#TrumpShutdown</a> <a href=\"https://twitter.com/hashtag/TrumpShutdown?src=hash&amp;ref_src=twsrc%5Etfw\">#TrumpShutdown</a> <a href=\"https://twitter.com/hashtag/TrumpShutdown?src=hash&amp;ref_src=twsrc%5Etfw\">#TrumpShutdown</a> <a href=\"https://twitter.com/hashtag/TrumpShutdown?src=hash&amp;ref_src=twsrc%5Etfw\">#TrumpShutdown</a> <a href=\"https://twitter.com/hashtag/TrumpShutdown?src=hash&amp;ref_src=twsrc%5Etfw\">#TrumpShutdown</a> <a href=\"https://twitter.com/hashtag/TrumpShutdown?src=hash&amp;ref_src=twsrc%5Etfw\">#TrumpShutdown</a> <a href=\"https://twitter.com/hashtag/GOPShutdown?src=hash&amp;ref_src=twsrc%5Etfw\">#GOPShutdown</a> <a href=\"https://twitter.com/hashtag/GOPShutdown?src=hash&amp;ref_src=twsrc%5Etfw\">#GOPShutdown</a></p>&mdash; mach229 (@mach229) <a href=\"https://twitter.com/mach229/status/954503720934535168?ref_src=twsrc%5Etfw\">January 19, 2018</a></blockquote>\n",
    "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and here is someone a little less friendly to the Democrats, quietmumbles. Each of these tweets contain data like the text of the actual tweet, the person who posted it, when they posted it and how many replies, retweets and likes it received. All of those different kinds of data need to be stored in a simple format so that it can be displayed in your Twitter client or in a browser or wherever else tweets travel. \n",
    "\n",
    "So the basic components of a tweet are easily represented using the tools we have so far -- basic numbers and strings and even booleans (is it a retweet or not?). Ah, but how do we bring all these together in a way that we can make sense of it consistently? Any ideas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"und\" dir=\"ltr\">Hey <a href=\"https://twitter.com/HillaryClinton?ref_src=twsrc%5Etfw\">@HillaryClinton</a> <a href=\"https://twitter.com/hashtag/ReleaseTheMemo?src=hash&amp;ref_src=twsrc%5Etfw\">#ReleaseTheMemo</a> <a href=\"https://twitter.com/hashtag/pleasedontsuicideanymore?src=hash&amp;ref_src=twsrc%5Etfw\">#pleasedontsuicideanymore</a><a href=\"https://twitter.com/hashtag/Obamagate?src=hash&amp;ref_src=twsrc%5Etfw\">#Obamagate</a> <a href=\"https://twitter.com/hashtag/maga?src=hash&amp;ref_src=twsrc%5Etfw\">#maga</a><a href=\"https://twitter.com/hashtag/SchumerShutdown?src=hash&amp;ref_src=twsrc%5Etfw\">#SchumerShutdown</a> <a href=\"https://twitter.com/hashtag/LockHerUp?src=hash&amp;ref_src=twsrc%5Etfw\">#LockHerUp</a> <a href=\"https://twitter.com/hashtag/LockThemAllUp?src=hash&amp;ref_src=twsrc%5Etfw\">#LockThemAllUp</a> <a href=\"https://twitter.com/hashtag/Gitmo?src=hash&amp;ref_src=twsrc%5Etfw\">#Gitmo</a></p>&mdash; Q.UIETMUMBLES (@quietmumbles) <a href=\"https://twitter.com/quietmumbles/status/954503731852267521?ref_src=twsrc%5Etfw\">January 19, 2018</a></blockquote>\n",
    "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at what a tweet really is under the hood. It is formatted in something called JSON (JavaScript Object Notation) but it will look very familiar to Python users. It is essentially a data specification that is very close to Python's built-in types with one addition, a dictionary. Let's have a look at these two tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiet = open(\"quiet.json\").read()\n",
    "print(type(quiet),\"\\n\")\n",
    "print(quiet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mach = open(\"mach.json\").read()\n",
    "print(type(mach),\"\\n\")\n",
    "print(mach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each case we have a string. Great. And it seems to have a lot of information in it. We see numbers and strings in the data. We also see list structures -- those square brackets we learned about last time. Ah but then there is something new. Curly braces or { }'s. While square brackets marked off lists, curly braces mark off *dictionaries*. Sometimes you don't want to store your data like a list, a sequential ordering of objects, with a first, a second, a third and so on.\n",
    "\n",
    "In some cases, like a literal dictionary (Websters?) we prefer to store data under \"keys\" like words rather than in a simple order. If we had to look up data in the dictionary by its numeric order in the text, we'd be lost. Instead, we search by word. This is the idea behind a dictionary in Python -- store the data according to words. \n",
    "\n",
    "To explore this idea, let's turn these tweet strings into Python objects. We will import two functions from the package \"json,\" \"loads\" and \"dumps.\" The former takes a string and makes Python objects, the latter takes a Python object (made up of built-in parts like numbers and lists and booleans and dictionaries) and turns it into a string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import dumps,loads\n",
    "\n",
    "tweet = loads(mach)\n",
    "print(type(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look up values in a dictionary by \"keys\". Not surprisingly, this is a method for the dictionary type of object. We use the same notation for subsetting as a list, the square brackets, but now we put the name of the data we want. \n",
    "\n",
    "Here are our choices of names, keys, that are associated with a tweet. What do you see? We then pull some data from the mach229 tweet.  If you need some help, consult [Twitter's description of their tweet objects. ](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text of the tweet..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet[\"full_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... a string representing when the tweet occurred (in UTC)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet[\"created_at\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and even a boolean to suggest if it has been truncated to the new 280 character limit or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet[\"truncated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your turn -- pull some data and tell us what you find\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in the quietmumbles tweet and tell us something about it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract some information about each user, mach229 and queitmumbles. \n",
    "# Who has the bigger pants on this social media platform?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can turn this from a dictionary, made up of these simple, built-in data types, back to a string that we could dump into a file. The command is \"dumps\" and there's an argument \"indent\" that might make the whole thing a little more readable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default, not so pretty\n",
    "\n",
    "print(dumps(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some indentation to mark off the different components, much more pretty :)\n",
    "\n",
    "print(dumps(tweet,indent=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this display, you can see that form of a dictionary clearly. It is made up of \"key-value\" pairs. The keys in this case are all strings (although they could be numbers or other \"immutable objects\" -- don't worry) and the value associated with the key is given on the other side of a colon and can be anything -- booleans, numbers, floats, lists, and even other dictionaries (check out the \"user\" key)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wanted to do this now in preparation for the next session when we will see an API (Application Programming Interface) that lets computers exchange information in a \"readable\" way. This format is very easy to process via a program in, say, Python. We'll see that in detail next time.\n",
    "\n",
    "**A shutdown quiz, of sorts**\n",
    "\n",
    "Let's review a little what we learned last time. Just as a refresher. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How many hashtags did quiet mumbles use in their tweet?\n",
    "\n",
    "\n",
    "\n",
    "# How many times did mach229 use the hashtag trumpshutdown?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, suppose that instead of a dictionary, we represent each tweet as a list. Here is a reduced set of information from a single tweet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet = [\n",
    "        \"schumershutdown\",\n",
    "        \"2018-01-20 23:59:59\",\n",
    "        \"TonyLimaPOL\",\n",
    "        False,\n",
    "        '<a href=\"http://tapbots.com/tweetbot\" rel=\"nofollow\">Tweetbot for iOS</a>',\n",
    "        \"RT @4everNeverTrump: Trump has been President for exactly one year.\\n\\nToday, there are mass protests against his administration and the fede\\u2026\"\n",
    "    ]\n",
    "\n",
    "# Extract the date it was tweeted\n",
    "\n",
    "\n",
    "# Extract the text of the tweet\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This format as you in your drill condensed this rather free-form data structure into something more rigid -- a table, or spreadsheet. Each tweet becomes a row and the columns represent different attributes of the tweet. We will work interchangeably between these different formats. In the case of tables, we have a long, long history of processing tabular data quickly and easily... and reproducibly. The code for Pandas, say, is readable and powerful. It can communicate easily some basic facts about the data with very little typing. Collections of JSON strings are harder to work with unless you are using a special database like Mongo that we will see later. \n",
    "\n",
    "So let's do a little Pandas review using the shutdown and the subsequent hashtag wars as an example. First, download the tweets per time period data sets \"schumer_timeseries.csv\" and \"trump_timeseries.csv\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the CSV files and store the DataFrames in variables called \"trump_time\" and \"schumer_time.\n",
    "# Have a look. What are you begging to do next?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.plotly import iplot, sign_in\n",
    "import plotly.graph_objs as go \n",
    "\n",
    "# sign into the service (get your own credentials!)\n",
    "sign_in(\"cocteautt\",\"8YLww0QuMPVQ46meAMaq\")\n",
    "\n",
    "# create a plot of two lines, one for each hashtag\n",
    "myplot_parts = [go.Scatter(x=trump_time[\"time\"],y=trump_time[\"count_trump\"],name=\"#trumpshutdown\"),\n",
    "                go.Scatter(x=schumer_time[\"time\"],y=schumer_time[\"count_schumer\"],name=\"#schumershutdown\")]\n",
    "\n",
    "# make a figure from these two lines...\n",
    "myfigure = go.Figure(data=myplot_parts)\n",
    "\n",
    "# ... and plot it (the filename is a convention plotly needs in case you want to use it later)\n",
    "iplot(myfigure,filename=\"hashtag_usage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to read in the data of  the raw tweets from over the weekend around the shutdown. The data collection is taking some time given the volume of tweets, but this will let us explore enough. Again, we have two files, one for #schumershutdown and one for #trumpshutdown -- called [\"schumer_all.csv\"](https://www.dropbox.com/s/m4xei1yz96juka5/schumer_all.csv.gz?dl=0) and [\"trump_all.csv\"](https://www.dropbox.com/s/itni7y9lqax12zh/trump_all.csv.gz?dl=0) respectively (hosted on Dropbox because they were a little big for Github). Load them into DataFrames called \"trump\" and \"schumer\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the trump_all.csv and schumer_all.csv, calling them \"trump\" and \"schumer\" respectively\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, have a look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set an option so we can display the full tweet text\n",
    "set_option(\"display.max_colwidth\",280)\n",
    "\n",
    "# have a look at a few of the tweets (remember your subsetting)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a list of the screen_names of the popular (frequent) tweeters of \n",
    "# either hashtag, and call it \"popular\" -- maybe 10 or so\n",
    "\n",
    "#       your code here...\n",
    "\n",
    "# then we can use the following construction to keep just those rows corresponding\n",
    "# to tweets with one of the given screen names, calling the resulting dataframe \"ptweets\"\n",
    "# uncomment the top line if you want to look at trump's popular tweeters instead of schumer's\n",
    "\n",
    "#ptweets = trump[trump[\"screen_name\"].isin(popular)]\n",
    "ptweets = schumer[schumer[\"screen_name\"].isin(popular)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look. Who tweeted a lot? In what time span? Do they look like a bot? What are we dying to do now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myplot_parts = [go.Scatter(x=ptweets[\"time\"],y=ptweets[\"screen_name\"],mode=\"markers\")]\n",
    "mylayout = go.Layout(autosize=False, height=1000,width=500,margin=go.Margin(l=150,r=50,b=100,t=100,pad=4))\n",
    "\n",
    "myfigure = go.Figure(data=myplot_parts,layout=mylayout)\n",
    "\n",
    "iplot(myfigure,filename=\"whoistweeting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Appendix**\n",
    "\n",
    "We include this code not because we expect you to master it yet... not by any stretch. But in the future, if you wonder where the data came from, you can consult this little section. Again, it include things about the language that we have not learned yet like looping. So please don't read this with any sense of dread or panic. We are on day 2 of a class that will have 30 meetings. This level of code  will make more sense around lesson 15 or so. So hold tight!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import loads\n",
    "\n",
    "# load in the JSON strings\n",
    "tsdata = open(\"ts2.json\").readlines()\n",
    "\n",
    "# create \n",
    "tsdates = []\n",
    "tsrawdates = []\n",
    "tsscreen = []\n",
    "tssource = [] \n",
    "tsretweet = [] \n",
    "tstext = []\n",
    "\n",
    "for data in tsdata[:-1]:\n",
    "    \n",
    "    tweet = loads(data)\n",
    "    \n",
    "    tsscreen.append(tweet[\"user\"][\"screen_name\"])\n",
    "    tssource.append(tweet[\"source\"])\n",
    "    tsretweet.append(\"retweet_status\" in tweet)\n",
    "    if \"full_text\" in tweet: tstext.append(tweet[\"full_text\"])\n",
    "    else: tstext.append(tweet[\"text\"])\n",
    "        \n",
    "    date = tweet[\"created_at\"]\n",
    "    month = \"01\"\n",
    "    mday = date[8:10]\n",
    "    hour = date[11:13]\n",
    "    rmin = date[14:16]\n",
    "    rsec = date[17:19]\n",
    "    tenmin = date[14:15]\n",
    "    \n",
    "    date = \"2018-01-\"+mday+\" \"+hour+\":\"+tenmin+\"0:00\"\n",
    "    tsdates.append(date)\n",
    "    \n",
    "    date = \"2018-01-\"+mday+\" \"+hour+\":\"+rmin+\":\"+rsec\n",
    "    tsrawdates.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssdata = open(\"ss2.json\").readlines()\n",
    "\n",
    "ssdates = []\n",
    "ssrawdates = []\n",
    "ssscreen = []\n",
    "sssource = [] \n",
    "ssretweet = [] \n",
    "sstext = []\n",
    "\n",
    "for data in ssdata[:-1]:\n",
    "    \n",
    "    tweet = loads(data)\n",
    "    \n",
    "    ssscreen.append(tweet[\"user\"][\"screen_name\"])\n",
    "    sssource.append(tweet[\"source\"])\n",
    "    ssretweet.append(\"retweet_status\" in tweet)\n",
    "    if \"full_text\" in tweet: sstext.append(tweet[\"full_text\"])\n",
    "    else: sstext.append(tweet[\"text\"])\n",
    "\n",
    "    date = tweet[\"created_at\"]\n",
    "    month = \"01\"\n",
    "    mday = date[8:10]\n",
    "    hour = date[11:13]\n",
    "    rmin = date[14:16]\n",
    "    rsec = date[17:19]\n",
    "    tenmin = date[14:15]\n",
    "    date = \"2018-01-\"+mday+\" \"+hour+\":\"+tenmin+\"0:00\"\n",
    "    ssdates.append(date)\n",
    "    \n",
    "    date = \"2018-01-\"+mday+\" \"+hour+\":\"+rmin+\":\"+rsec\n",
    "    ssrawdates.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "# create two functions to count the number of times each\n",
    "# hashtag shows up in a time period\n",
    "\n",
    "def count_schumer(x):\n",
    "    return(sum(x==\"schumershutdown\"))\n",
    "    \n",
    "def count_trump(x):\n",
    "    return(sum(x==\"trumpshutdown\"))\n",
    "\n",
    "# group the data by 10 minute time periods and count the\n",
    "# number of each hashtage found during our search in each period\n",
    "\n",
    "df = DataFrame({\"time\":ssdates+tsdates,\"hashtag\":[\"schumershutdown\"]*len(ssdates)+[\"trumpshutdown\"]*len(tsdates)})\n",
    "df = df.groupby([\"time\"]).agg({\"hashtag\":[count_schumer,count_trump]})\n",
    "\n",
    "# some tedious stuff to turn this back into a proper data frame. \n",
    "# esoteric relabling that's easy to describe but just a little early.\n",
    "\n",
    "df.columns = df.columns.droplevel(0)\n",
    "df = df.reset_index()\n",
    "\n",
    "# look at the tail of the data frame\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schumer_time = df[[\"time\",\"count_schumer\"]][df[\"count_schumer\"]>0][1:]\n",
    "schumer_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_time = df[[\"time\",\"count_trump\"]][df[\"count_trump\"]>0][1:]\n",
    "trump_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trump_time.to_csv(\"trump_time.csv\")\n",
    "schumer_time.to_csv(\"schumer_time.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssstext = [s.encode(\"ascii\",\"ignore\") for s in sstext]\n",
    "ststext = [s.encode(\"ascii\",\"ignore\") for s in tstext]\n",
    "ssstext[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "schumer = DataFrame({\"text\":ssstext,\n",
    "                     \"time\":ssrawdates,\n",
    "                     \"hashtag\":[\"schumershutdown\"]*len(ssdates),\n",
    "                     \"screen_name\":ssscreen,\n",
    "                     \"retweet\":ssretweet,\n",
    "                     \"source\":sssource})\n",
    "\n",
    "trump = DataFrame({\"text\":ststext,\n",
    "                     \"time\":tsrawdates,\n",
    "                     \"hashtag\":[\"trumpshutdown\"]*len(tsdates),\n",
    "                     \"screen_name\":tsscreen,\n",
    "                     \"retweet\":tsretweet,\n",
    "                     \"source\":tssource})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trump.shape,schumer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schumer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump.to_csv(\"trump_all.csv\",index=False)\n",
    "schumer.to_csv(\"schumer_all.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
