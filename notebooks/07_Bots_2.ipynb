{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we are going to dig deeper into bots and start to look at them not simply as responding to events in the world (retweeting, say), but as \"conversational interfaces\" to information and services - voice. To get there, we need tools to help us interpret what people are saying to our bot and how we are going to respond. \n",
    "\n",
    "We will assume that there are APIs (which we will use) for Alexa and the like that handle speech recognition and text-to-speech generation. Our job will be editorial. What do we say? \n",
    "\n",
    "\n",
    "Regular Expressions\n",
    "-------------------\n",
    "\n",
    "<img src=https://imgs.xkcd.com/comics/regular_expressions.png width=400>\n",
    "\n",
    "\n",
    "In this portion of class, we are going to work with a \"language\" for expressing patterns in text. By \"pattern\" I mean specifying repetitions of symbols -- words or punctuation or sequences of numbers or any combination of these. Given a collection of text, for example, regular expressions might help you find dates or telephone numbers or URLs or email addresses -- all of these obey certain formatting rules. \n",
    "\n",
    "Regular expressions, then, are a way to describe these formatting rules so that we can search a body of text for them. Sometimes we are doing this because we want to find lists of facts about people (email addresses and their telephone numbers, say), creating structured data out of unstructured data (a common theme in this class). And sometimes we appeal to regular expressions because they help us in the act of \"cleaning\" data -- we might be given a date column in a data set that contains dates in two different formats (y-m-d and m/d/y, say) and we need to transform them into just one consistent format throughout. \n",
    "\n",
    "The patterns we express might also be about content. Can we detect the gender of sources? Can we find new memes in a stack of text? Unlike the proto-natural language processing we saw with TextBlob, regular expressions deal with words as patterns of characters. There is no understanding here about parts of speech or grammar. Just patterns of symbols -- characters, numbers, and emoji, even.\n",
    "\n",
    "**Trump's State of the Union Address**\n",
    "\n",
    "To explain how regular expressions work, we will look at a large collection of text -- the transcript of the SOTU from January. Lots of things were discussed and we can sort through topics, his speech patterns and so on.\n",
    "\n",
    "[The full transcript is here](https://www.whitehouse.gov/briefings-statements/president-donald-j-trumps-state-union-address/)\n",
    "\n",
    "[A file with one line per sentence is here](https://raw.githubusercontent.com/computationaljournalism/columbia2018/master/data/sotu_sentences.txt)\n",
    "\n",
    "You can download the file in a browser window and save it to your computer or you can use the `requests` package to access the file from Python directly. You can choose either but for now, let's download the file and read it in directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file and read in the contents. recall\n",
    "# that this will take each line in the file and make\n",
    "# it an entry is a list. so the entire sotu is now a list\n",
    "# of strings, one string per sentence spoken.\n",
    "\n",
    "sentences = open(\"sotu_sentences.txt\").readlines()\n",
    "\n",
    "print(\"The object 'sentences' is of type\", type(sentences))\n",
    "print(\"There are\", len(sentences), \"sentences in the list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is a slice with the first five entries\n",
    "# (those having index 0, 1, 2, 3 and 4)\n",
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aside: List comprehensions**\n",
    "\n",
    "Notice that each sentence has a \"newline\" at the end of it, the `\\n` character. This is actually a common problem so it's worth mentioning. When you read in HTML, for example, the format doesn't care if you specify a heading like this\n",
    "    \n",
    "    <h1>A title</h1>\n",
    "\n",
    "or like this\n",
    "\n",
    "    <h1>         A title            </h1>\n",
    "    \n",
    "or like this\n",
    "\n",
    "    <h1>\n",
    "              A\n",
    "                    title\n",
    "                                 </h1>\n",
    "\n",
    "So we are routinely needing to tidy up text to make it more readable for a human, and to provide it with a bit of reglarity so any automated text processing is cleaner. This will happen with just about any data you come across -- some kind of regularizing is going to be needed, especially with text.\n",
    "\n",
    "The pretext of cleaning data also gives us a chance to introduce something new. We can remove the newlines from the end of each sentence using something called a 'list comprehension.' This is a new piece of Python syntax that lets us create new lists from old ones, transforming each element of the old list. It is an alternative to a loop, and is, well, **pretty snazzy. ** \n",
    "\n",
    "If we wanted to remove the `\\n` from each sentence we might do something like the following if we had to use a loop. It goes over each sentence and strip()'s off the whitespace from the start and end of the string. Whitespace includes spaces and tabs and newlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentences = []\n",
    "\n",
    "for s in sentences:\n",
    "    new_sentences.append(s.strip())\n",
    "    \n",
    "new_sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the difference? The `\\n`'s are gone!\n",
    "\n",
    "To sum, we iterate through the list of sentences. Each sentence is `strip()`'d, has all the \"white space\" removed from its front and back end, and then appended to the new_sentences list. I hope you agree that this is kind of clunky notation. \n",
    "\n",
    "A \"list comprehension\" is a cleaner way to accomplish the same thing. So, let's reread the data and apply this new code construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the speech\n",
    "sentences = open(\"sotu_sentences.txt\").readlines()\n",
    "\n",
    "# use a list comprehension to strip out the newlines\n",
    "new_sentences = [s.strip() for s in sentences]\n",
    "\n",
    "new_sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second expression above says that we cycle through all the elements in `sentences`, letting the variable name `s` represent each one in turn. The first element, for example, becomes the start of a new list, and it has had `.strip()` applied to it. The second element is then `strip()`'d and stored in the new list and so on. As you can see, a list comprehension reads like our loop in the previous cell and behaves similarly -- but it is syntactically nicer. \n",
    "\n",
    "You can also limit the number of results included in the new list by adding an `if` clause -- a logical expression. As the list comprehension is running through the elements of the old list, it can chose whether or not to incude it in the new list via a logical expression. \n",
    "\n",
    "Suppose, for example, we want to keep only sentences that contain the word \"wall\". In terms of programming, we can use the operator `in`. We've seen this logical operator before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"tide\" in  'A new tide of optimism was already sweeping across our land.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"cyclone\" in  'A new tide of optimism was already sweeping across our land.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this, in the expression below we run through each entry in the list `sentences`, labeling them `s` in turn, and keeps only those with at least one occurrence of the word \"wall\". (Here we don't save the new, reduced and transformed list -- we just have a look at it.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sentences if \"wall\" in s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to make a new list in a loop we might do the following. Hopefully you see the code above is slicker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentences = []\n",
    "\n",
    "for s in sentences:\n",
    "    if \"wall\" in s:\n",
    "        new_sentences.append(s)\n",
    "        \n",
    "new_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's list comprehensions -- new lists from old with a syntax that's a lot cleaner to read than a loop. We'll be using them for the remainder of this lesson. Keep in mind, however, that while we are using them for text, they can be used for any list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of some numbers\n",
    "x = [2,5,4,7,8,2,4,5]\n",
    "\n",
    "# a list comprehension that just keeps two times\n",
    "# the entries that are larger than 3\n",
    "[2*i for i in x if i>3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK back to the SOTU. We'll read it in fresh and take out all the newlines. Here's a clean way to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = [s.strip() for s in open(\"sotu_sentences.txt\").readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you understand the example above. This construction is pretty powerful!\n",
    "\n",
    "**Back to the transcript and regular expressions**\n",
    "\n",
    "Python implements the regular expression search framework through a package called `re` (aptly named). We are going to make use of the `search()` function in this package. It takes a pattern definition (a regular expression) and searches for it in a string, returning every match it finds. You can use this in a list comprehension because when a `search()` finds a regular expression pattern it is treated as `True` in an `if` statement. When it can't find the pattern, it is treated as `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from re import search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Literals** \n",
    "\n",
    "As a way of specifying patterns, let's start with so-called \"literals\" -- these characters just match themselves. For example, the literal *\"wall\"* matches the following sentences from Trump’s transcript. This should be equivalent to the results we had by using the operator `in`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sentences if search(\"wall\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the literal *\"wall\"* with a search for *\"immigration\"\n",
    "*. Do you find any sentences matching this pattern? What other searches like this might you do to highlight sentences about immigration? Or other topics that this search suggests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in the search for \"wall\" we also had \"walls\" turn up. If we were interested in \"media\" we might look for the **literal string** consisting of the letters m-e-d-i-a. \n",
    "\n",
    "See what we get..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sentences if search(\"media\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, well, that's not what we wanted at all. So, how do we get just the word \"media\"? Let's take a moment and write down the kinds of patterns in text we might be interested in finding, either from this speech or from your reporting or other work. What sorts of things do you have to specify? I mean word boundaries seem like a good idea so we can differentiate \"media\" from \"immediate\". What else do you need?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get us to more complex searches, we need some way to express these ideas. And that's where metacharacters come to the rescue!\n",
    "\n",
    "**In Walks Metacharacters**\n",
    "\n",
    "Any character except for [ ]\\\\^\\$.|?\\*+( )\\{ and \\} can be used to specify a literal -- they match a single instance of themselves. The string *\"wall\"* represented a series of literals and to have a match we need to find a \"w\" followed by an \"a\" followed by an \"l\" and so on. The non-literals, on the other hand, are known as **metacharacters** and are used to specify much more complicated text patterns.\n",
    "\n",
    "They help us specify \"whitespace,\" word boundaries, sets or classes of literals, the beginning and end of a line, and various alternatives (\"war\" or \"peace\"). For example **^ represents the start of a line.** Let's look at what we get by searching the SOTU for a pattern than includes this character.\n",
    "\n",
    "*(We are now going to preface our strings representing regular expressions with the letter `r`. We have seen `u` before to mean Unicode. Here `r` means a \"raw\" string. Basically it tells Python that every character is to be interpreted as it is. We have seen that `\\n` in a string means a single character, newline. In a raw string, `\\n` is interpreted as two characters, a backslash and an \"n\". This will be important and is really a way around the fact that regular expressions and Python use metacharacters to build things like newlines or  to represent the beginning of a sentence.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sentences if search(r\"^I am\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a new sentence starter and see what you find..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some Help**\n",
    "\n",
    "To interpret what a regular expression is doing, we can use a special tool from [regexper.com](http://regexper.com/). It takes regular expressions and renders them graphically so you can get a better sense of how the machinery is functioning. For example, here is the display for our *\"^I am\"* example.\n",
    "\n",
    "[Graphical view of the pattern \"^I am\"](http://regexper.com/#%5EI%20am)\n",
    "\n",
    "You see a window where you can change the regular expression and then a graphical interpretation of what you've asked for. This is an extremely handy tool. (Notice that you don't have to include the quotes or the `r` in the regexper.com interface.) \n",
    "\n",
    "Now, if specifying the start of a line is important, having a special character for the end of a line is likely to be handy also. **The \\$ represents the end of a line.** Consider the pattern *\"road.\\$\"*. Here are the lines it matches the SOTU. Do you notice anything odd here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sentences if search(r\"road.$\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see two sentences that end in \"road.\" but really end with the world \"abroad.\" Ah but notice that we also have one sentence that ends with \"road?\". \n",
    "\n",
    "What's going on here? Well, the dot, \".\", is a metacharacter and represents a wildcard. It is used to refer to any character. So, *road.\\$* will match lines that end in \"road.\" or \"road?\" or even \"road9\" (should the transcriber be typing sloppily one day). Have a look at this at regexper.com.\n",
    "\n",
    "[Graphical view of the pattern \"road.\\$\"](http://regexper.com/#road.%24)\n",
    "\n",
    "Putting a backslash \\\\ before one of the special metacharacters [ ] \\\\^\\$/?\\*+()\\{ and \\} lets us include these in a pattern as literals -- in technical terms, we have \"escaped\" the special meaning of these characters and they return to their literal meanings. \n",
    "\n",
    "Consider the pattern *\"\\\\\\$2\"*. With the backslash, \\$ no longer means the end of a line. We have returned the dollar sign to its literal meaning and the following lines match from the Trump transcript. \n",
    "\n",
    ">Now, the first \\$24,000 earned by a married couple is completely tax-free.'\n",
    "<br><br>\n",
    ">'A typical family of four making \\$75,000 will see their tax bill reduced by \\$2,000 — slashing their tax bill in half.'\n",
    "\n",
    "And to bring the point home, look at the following.\n",
    "\n",
    "[Graphical view of the pattern \"\\\\\\$2\"](http://regexper.com/#%5C%242)\n",
    "\n",
    "So, given this, what do we need to do to match sentences ending with the word \"country\" followed by a period?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A character class matches a single character out of all the possibilities contained in brackets, [  ]** — There are certain rules that apply when specifying these classes that we’ll get to in a second. Let's look at the pattern *\"[Tt]onight\"* and see what lines it matches in the transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sentences if search(r\"[Tt]onight\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Graphical view of the pattern \"[Tt]onight\"](http://regexper.com/#%5BTt%5Donight)\n",
    "\n",
    "Keep in mind that while there might be lots of options in the square brackets, we are only trying to match one character out of this group. The graphical display makes this clear. We'll talk about specifying more than one match in a few minutes.\n",
    "\n",
    "In terms of the rules that work within character classes, you can specify a range of letters [a-z] or [A-Z] or numbers [0-9] — Keep in mind that the order within the character class doesn’t matter, it specifies a bag of characters from which we select one item. Let's look at the pattern *\"[0-9] years\"* and see which sentences it will match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sentences if search(r\"[0-9] years\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Graphical view of the pattern \"[0-9] years\"](http://regexper.com/#%5B0-9%5D%20years)\n",
    "\n",
    "It's important to keep in mind what's being matched here. The expression *\"[0-9] years\"* will match \"5 years\" in the sentence that started \"CJ served 15 years in the Air Force\". The expression wants a number then a space then the word \"years\". Get it? \n",
    "\n",
    "**When used at the beginning of a character class ^ is also a metacharacter and it indicates matching characters NOT in the indicated class.** So the pattern *\"[^?.]\\$\"* will match sentences that don't end in a period or a question mark (you don't have to \"escape\" characters in a character class -- or between [ and ]). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sentences if search(r\"[^?.]$\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a large number of quotes in this list. Maybe we should look for quoted statements next? Anyway, here is the graphical representation of the expression.\n",
    "\n",
    "[Graphical view of the pattern \"[^?.]\\$\"](http://regexper.com/#%5B%5E%3F.%5D%24)\n",
    "\n",
    "Continuing on our survey of metacharacters, the **vertical bar \"|\" translates to “or”** — We can use it to combine expressions, the subexpressions being called alternatives. The expression *\"good|bad\"* will match these lines from transcript file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sentences if search(r\"good|bad\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll jump ahead just briefly and say that we can solve the problem of matching \"goodness\" and \"badly\" when all we want are the words \"good\" or bad\". Some collections of characters, some \"character classes\" are used so often that they are given special notation. For example `\\w` is a word character and `\\b` represents a character class of \"word boundaries\". Here's a (not elegant but works) way to say you want \"good\" or \"bad\" alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sentences if search(r\"\\bgood\\b|\\bbad\\b\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will give a complete set of character classes at the end of this section.\n",
    "\n",
    "Returning to choices, of course we can join several alternatives together. Consider *\"year|month|day\"*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sentences if search(r\"day|month|year\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, here we see a lot of matches to patterns like \"birthday\" or \"someday\". Both contain the literal *\"day\"* but they might not be what we had in mind. \n",
    "\n",
    "[Graphical view of the pattern \"year|month|day\"](http://regexper.com/#year%7Cmonth%7Cday)\n",
    "\n",
    "Oh and the alternatives separated by \"|\" can be any real expressions and not just literals. Here we ask for time or money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sentences if search(\"[0-9] year|\\$[0-9]\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again, regexper.com to help us out.\n",
    "\n",
    "[Graphical view of the pattern \"[0-9] year|\\$[0-9]\"](https://regexper.com/#%5B0-9%5D%20year%7C%5C%24%5B0-9%5D)\n",
    "\n",
    "**Subexpressions are often contained in parentheses (more metacharacters) to constrain the\n",
    "alternatives in some way.** For example *\"^(I will|I am)\"* matches either expression, but at the start of a sentence. \n",
    "\n",
    "Later we will see that we can identify each subexpression separately,allowing us to extract (or capture) the content they match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sentences if search(\"^(I will|I am)\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the graphical representation -- notice the new reference to groups that are formed by the parentheses.\n",
    "\n",
    "<a href=https://regexper.com/#%5E%28I%20will%7CI%20am%29>Graphical view of the pattern \"^(I will|I am)\"</a>\n",
    "\n",
    "We're building up quite a vocabulary. Try a more complex expression on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we leave this, let's use the shorthand \\\\b  for word boundaries and our parentheses construction to match what we really wanted with our original search a few cells back, *\"\\b(day|month|year)\\b\"*. Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sentences if search(r\"\\b(day|month|year)\\b\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The question mark indicates that the indicated expression is optional.** The expression *\"George( W\\\\.)? Bush\"* will match references to “George W. Bush” or just “George Bush”.\n",
    "\n",
    "<a href=http://regexper.com/#George(%20W%5C.)%3F%20Bush>Graphical view of the pattern \"George( W\\\\.)? Bush\"</a>\n",
    "\n",
    "**The \\* and + signs are metacharacters used to indicate repetition** — the \\* means “any number, including zero, of the item” and + means “at least one of the item”. So we can specify clauses after a colon with the following regular expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in sentences if search(r\":.+$\",s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(You see some errors here with how the sentences were pulled. You can blame TextBlob.) Now, to make this seem a bit more practical, we are going to consider another data source. You can download some of it, but it's big. It's essentially all of Jeb Bush's emails while he was in office in Florida. I mean literally in `mbox` format. The site is show here via the Internet Archive...\n",
    "<br><br>\n",
    "<img src=https://github.com/computationaljournalism/columbia2018/raw/master/images/jb2.jpg style=\"width: 65%; border: #000000 1px outset;\"/>\n",
    "<br><br>\n",
    "... because this was such a bad idea, they took the site down quickly. \n",
    "<br><br>\n",
    "<img src=https://github.com/computationaljournalism/columbia2018/raw/master/images/jb1.jpg style=\"width: 65%; border: #000000 1px outset;\"/>\n",
    "<br><br>\n",
    "Why a bad idea? Well, no one masked any possibly sensitive data from the emails. So it's easy to find phone numbers or social security numbers or military ID's in these text files.\n",
    "\n",
    "For example, to grab phone numbers, we look for digits that are separated by hyphens. For social security numbers or phone numbers we could use this expression *\"[0-9]+-[0-9]+-[0-9]+\"*. Why? Here's a series of lines that match this pattern from Jeb's emails.\n",
    "\n",
    ">Phone: 407-240-1891<br><br>In reference to your letter dated october 29, 1998 in which you offer to help me with my inmigration question, i am a us citizen who is petition for my husband (a mexican citizen) petition #SRC-98-204-50114 his name is FRANCISCO JAVIER CORTEZ HERNANDEZ.<br><br>Fax: 407-888-2445<br><br>Pager: 850-301-8072<br><br>Cell: 407-484-8167<br><br>The Reverned uses his pager# 813-303-4726 to get in contact with, or you may email\n",
    "and I will get in touch with him. <br><br>\n",
    "\n",
    "And from regexper.com... \n",
    "\n",
    "<a href=http://regexper.com/#%5B0-9%5D%2B-%5B0-9%5D%2B-%5B0-9%5D%2B>Graphical view of the pattern \"[0-9]+-[0-9]+-[0-9]+\"</a>\n",
    "\n",
    "In words, we are looking for one or more numbers followed by a hyphen, followed by one or more numbers, and then another hyphen, and finally one or more numbers.\n",
    "\n",
    "**The curly braces \\{ and \\} are referred to as interval quantifiers** — they let us specify the exact number of occurences of a pattern, its minimum, maximum or an acceptable range. For a Social Security Number we might want \"[0-9]{3}-[0-9]{2}-[0-9]{4}\", for example - three numbers, a hyphen, two numbers, a hyphen then four numbers.  \n",
    "\n",
    "<a href=https://regexper.com/#%5B0-9%5D%7B3%7D-%5B0-9%5D%7B2%7D-%5B0-9%5D%7B4%7D>View of the pattern \"[0-9]{3}-[0-9]{2}-[0-9]{4}\"</a>\n",
    "\n",
    "Here's the full list of what you can do with the curly braces as metacharacters. \n",
    "<table>\n",
    "          <tr>\n",
    "            <th>Expression</th>\n",
    "            <th>What does it mean?</th>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>{3}</td>\n",
    "            <td>Looks for 3 occurences of a pattern</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>{,3}</td>\n",
    "            <td>Matches at most 3 occurrences</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>{3,}</td>\n",
    "            <td>Matches at least 3 occurrences</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>{3,5}</td>\n",
    "            <td>Matches between 3 and 5 occurrences</td>\n",
    "          </tr>\n",
    " </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this information, how would we skim these emails for specific kinds of numbers? Credit card numbers? Phone numbers? VIN numbers?\n",
    "\n",
    "**Groupings.** In most implementations of regular expressions, the parentheses not only limit the scope\n",
    "of alternatives divided by a “|”, but also can be used to “remember” text matched by the\n",
    "subexpression enclosed. We refer to the matched text with \\1, \\2, etc., depending on how many parenthese we have. \n",
    "\n",
    "As an example, the expression\n",
    "*\" ([a-zA-Z]+) \\1 \"* will match these lines in Jeb Bush’s inbox from January of 2000.\n",
    "\n",
    ">I feel this is a **win win** situation for the Governor, the Reverend and the people that need help.<br><br>I insisted **that that** be the outcome in that court and that we did not recede from that position.<br><br>I guess you're embarrassed **that that** line got out.<br><br>\n",
    "\n",
    "The pattern is asking for repeated words. We highlighted them in the text above. Also have a look at the graphical representation of this regular expression.\n",
    "\n",
    "<a href=http://regexper.com/#%20(%5Ba-zA-Z%5D%2B)%20%5C1%20>Graphical view of the pattern \" ([a-zA-Z]+) \\1 \"</a>.\n",
    "\n",
    "**Substitution**\n",
    "\n",
    "Groupings are also helpful when you want to make substitutions. We have already seen that string types offer you the opportunity to replace text..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'We will work to fix bad trade deals and negotiate new ones.'\n",
    "s.replace(\"We\",\"You\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `re` package includes a function `sub` that lets you act on groups. Here we define a group to be a dollar value and extract it. With this kind of construction, you can see how you might start to pull structured information from unstructured text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import sub\n",
    "\n",
    "s = \"These changes alone are estimated to increase average family income by more than $4,000.\"\n",
    "\n",
    "# pull out the dollar value\n",
    "sub(r\".*\\$([0-9,]+).*\",r\"\\1\",s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To Sum**\n",
    "\n",
    "The presentation here is meant to give you a flavor of how regular expressions are structured; you have seen the major metacharacters and to use them to create patterns. Below I provide a useful cheat sheet to remember what the different metacharacters mean and what some of the useful shorthand character classes are. In addition, I can recommend [an interactive cheat sheet](https://www.debuggex.com/cheatsheet/regex/python), and the site [http://www.regular-expressions.info/](http://www.regular-expressions.info/) is also an excellent resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metacharacters**\n",
    "\n",
    "<table>\n",
    "          <tr>\n",
    "            <th>Metacharacter</th>\n",
    "            <th>What does it do?</th>\n",
    "            <th>Examples</th>\n",
    "            <th>Matches</th>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>^</td>\n",
    "            <td>Matches beginning of line</td>\n",
    "            <td>^abc</td>\n",
    "            <td>abc, abcdef.., abc123</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>\\$</td>\n",
    "            <td>Matches end of line</td>\n",
    "            <td>abc\\$</td>\n",
    "            <td>my:abc, 123abc, theabc</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>.</td>\n",
    "            <td>Match any character</td>\n",
    "            <td>a.c</td>\n",
    "            <td>abc, asg, a123c</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>[...]</td>\n",
    "            <td>Matches one character contained in brackets</td>\n",
    "            <td>[abc]</td>\n",
    "            <td>a,b, or c</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>[^...]</td>\n",
    "            <td>Matches one character not contained in brackets</td>\n",
    "            <td>[^abc]</td>\n",
    "            <td>xyz, 123, 1de</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>[a-z]</td>\n",
    "            <td>Matches one character between 'a' and 'z'</td>\n",
    "            <td>[b-z]</td>\n",
    "            <td>bc, mind, xyz</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>\\*</td>\n",
    "            <td>Matches character before \\* 0 or more times</td>\n",
    "            <td>ab\\*c</td>\n",
    "            <td>abc, abbc, ac</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>+</td>\n",
    "            <td>Matches character before + one or more times</td>\n",
    "            <td>a+c</td>\n",
    "            <td>ac, aac, aaac,</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>?</td>\n",
    "            <td>Matches the character before the ? zero or one times. Also, used as a non-greedy match</td>\n",
    "            <td>ab?c</td>\n",
    "            <td>ac, abc</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>{x}</td>\n",
    "            <td>Match exactly 'x' number of times</td>\n",
    "            <td>(abc){2}</td>\n",
    "            <td>abcabc</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>{x,}</td>\n",
    "            <td>Match 'x' number of times or more</td>\n",
    "            <td>(abc){2,}</td>\n",
    "            <td>abcabc, abcabcabc</td>\n",
    "          </tr>\n",
    "           <tr>\n",
    "            <td>{,x}</td>\n",
    "            <td>Match up to 'x' number of times</td>\n",
    "            <td>(abc){2,}</td>\n",
    "            <td>abcabc, abcabcabc</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>{x,y}</td>\n",
    "            <td>Match between 'x' and 'y' times.</td>\n",
    "            <td>(a){2,4}</td>\n",
    "            <td>aa, aaa, aaaaa</td>\n",
    "          </tr>\n",
    "           <tr>\n",
    "            <td>|</td>\n",
    "            <td>OR operator</td>\n",
    "            <td>abc|xyz</td>\n",
    "            <td>abc or xyz</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>(...)</td>\n",
    "            <td>Capture anything matched</td>\n",
    "            <td>(a)b(c)</td>\n",
    "            <td>Captures 'a' and 'c'</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>(?:...)</td>\n",
    "            <td>Non-capturing group</td>\n",
    "            <td>(a)b(?:c)</td>\n",
    "            <td>Captures 'a' but only groups 'c'</td>\n",
    "          </tr>\n",
    "           <tr>\n",
    "            <td>\\</td>\n",
    "            <td>Escape the character after the backslash; or create a special sequence (like word boundaries, \\b, or a character representing a space, \\s.</td>\n",
    "            <td>a\\sc</td>\n",
    "            <td>a c</td>\n",
    "          </tr>\n",
    "        </table>\n",
    "\n",
    "The special \"metacharacters\" () [] {} ^ \\$ . | \\* + ?  and \\\\ become \"literals\" again if you put a \\\\ in front of them -- That is, \\\\. matches a period and is no longer the wild card. We say we have \"escaped\" the metacharacter.\n",
    "\n",
    "**Shorthand character classes**\n",
    "\n",
    "<table>\n",
    "          <tr>\n",
    "            <td>\\d</td>\n",
    "            <td>Match any digit (0-9)</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>\\D</td>\n",
    "            <td>Match any non digit</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td >\\t</td>\n",
    "            <td>Match a tab</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>\\n</td>\n",
    "            <td>Match a new line</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>\\r</td>\n",
    "            <td>Match a carriage return</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>\\s</td>\n",
    "            <td>Matches a space character (space, \\t, \\r, \\n)</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>\\S</td>\n",
    "            <td>Matches any non-space character </td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>\\b</td>\n",
    "            <td>Word boundary</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>\\B</td>\n",
    "            <td>Non word boundary</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>\\w</td>\n",
    "            <td>Matches any one word character [a-zA-Z_0-9]</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>\\W</td>\n",
    "            <td>Matches any one non word character</td>\n",
    "          </tr>\n",
    "          </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Coming Age of Conversational Bots\n",
    "--------------------------------------\n",
    "<hr>\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1000/1*-uuhR1UX709LfUnDiS30Rg.png\"  style=\"width: 65%;\"/>\n",
    "<br>\n",
    "\n",
    "Thursday, we will have a bit more history courtesy of Mark Lavallee and Emily. In the meantime, FastCompany  published a nice history of  a particular kind of software robot: [How The New, Improved Chatbots Rewrite 50 Years Of Bot History](http://www.fastcompany.com/3059439/why-the-new-chatbot-invasion-is-so-different-from-its-predecessors). Chatbots are really a conversation-based interfaces to services of various kinds. Sometimes the logic behind their inner workings is incredibly complex, but other times their operation is very service-oriented and shallow. Sometimes they are reading from a script, sometimes machine learning helps direct responses.\n",
    "\n",
    "The FastCompany article makes the point that while strands of artificial intelligence research has been obsessed with making a both that was believably human (or perhaps with the potential for one), the latest incarnations of these programs exist \"to help you get things done.\" They have grown plentiful using the scale of new platforms (Facebook, Twitter, and so on) and are fit tidily into their business interests.\n",
    "\n",
    "Here's a snippet.\n",
    "\n",
    ">But over the past few years, chatbots have made a comeback. With advancements in processing power, bots now have a better ability to interpret natural language and learn from users over time. Just as importantly, big companies like Facebook, Apple, and Microsoft are now eager to host our interactions with various services, and offer tools for developers to make those services available. Chatbots easily fit into their larger business models of advertising, e-commerce, online services, and device sales. Meanwhile, services that want to reach hundreds of millions of customers on a platform like Messenger will be helping to write the chat scripts.\n",
    "<br><br>\"A lot of the things that were barriers to us back then are no longer barriers to us today because of the evolution of the way technology works,\" Hoffer says.\n",
    "<br><br>\n",
    "Crucially, these bots are meant to be useful out of the gate, ... they no longer need conversation as a crutch for mass adoption. Sure, Apple’s Siri knows how to break the ice with a few jokes, but it largely exists to help you get things done. Rival assistants from Google and Amazon don’t exhibit much personality at all. Utility is winning out because the technology allows for it.\n",
    "\n",
    "The article ends with a comment about early artificial intelligence researcher Joseph Weizenbaum. Weizenbaum created something called ELIZA, a computer program that was modeled after a psychiatrist (or an \"active listener\"). \n",
    "\n",
    ">If the latest round of chatbots succeed, they might prove that Weizenbaum, the creator of ELIZA, was right all along. These machines are not warm and cuddly replacements for the human intellect. They’re just another set of tools—an evolution of the apps that have served us for years.\n",
    "\n",
    "As an aside, Weizenbaum didn't create ELIZA as a state of the art conversational program. He was, in fact, troubled by its positive reception, and later in life he wrote about the limits of artificial intelligence. The passage below is from his 1976 text [Computer power and human reason](https://en.wikipedia.org/wiki/Computer_Power_and_Human_Reason). He closes the third chapter with this image.\n",
    "\n",
    ">Sometimes when my children were still little, my wife and I would stand over them as they lay sleeping in their beds. We spoke to each other only in silence, rehearsing a scene as old as mankind itself. It is as Ionesco told his journal: ‘Not everything is unsayable in words, only the living truth.\n",
    "\n",
    "Beautiful, right? For a data class, it's a great reminder that data will always exist at distance from lived experience. We can try to pile more and more data on a given situation or phenomenon. But no matter how big our data gets, we are still missing something. That's why we've been stressing how your choice of data is a creative act.\n",
    "\n",
    "Before we startup ELIZA, our dear friend Suman has listed out a number of identifiable elements to think about when you are designing a conversation. Again, not all of these will apply as we might be very functionally-oriented, but they are something to remember.\n",
    "\n",
    "#### Some Identifiable Elements of Conversation:\n",
    "\n",
    "| Element of Conversation | Possible Techniques to Compute/ Quantify |\n",
    "| ------ | ----------- |\n",
    "|1. Notifications/ Recalling relevant things   |  Time Series Analysis, Alerting, Keyword caches |\n",
    "|2. Learning topics in context | Topic Mining/Modeling - extract the topic from the words in text |\n",
    "|3. Understanding Social Networks (offline and online)  | Network Science, the study of the structure of how things are connected and how information flows through it |\n",
    "|4. Responding to Emotion  | Sentiment Analysis\n",
    "|5. Having Episodic Memory  | Some kind of graphical model, [see Aditi's data post](https://medium.com/@aditinair/episodic-memory-modeling-for-conversational-agents-7c82e25b06b4#.9k65cziqw). |\n",
    "|6. Portraying Personality  | Decision Tree, which is a tree-like graph or model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. |\n",
    "\n",
    "\n",
    "\n",
    "**ELIZA**\n",
    "\n",
    "Anyway, today we are going to work on the basics of a chatbot. Below we have the ELIZA program in Python form. Execute it and interact. You type \"quit\" to get out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import match, IGNORECASE\n",
    "from random import choice\n",
    " \n",
    "reflections = {\n",
    "    \"am\": \"are\",\n",
    "    \"was\": \"were\",\n",
    "    \"i\": \"you\",\n",
    "    \"i'd\": \"you would\",\n",
    "    \"i've\": \"you have\",\n",
    "    \"i'll\": \"you will\",\n",
    "    \"my\": \"your\",\n",
    "    \"are\": \"am\",\n",
    "    \"you've\": \"I have\",\n",
    "    \"you'll\": \"I will\",\n",
    "    \"your\": \"my\",\n",
    "    \"yours\": \"mine\",\n",
    "    \"you\": \"me\",\n",
    "    \"me\": \"you\"\n",
    "}\n",
    " \n",
    "actions = [\n",
    "    [r'I need (.*)',\n",
    "     [\"Why do you need {0}?\",\n",
    "      \"Would it really help you to get {0}?\",\n",
    "      \"Are you sure you need {0}?\"]],\n",
    " \n",
    "    [r'Why don\\'?t you ([^\\?]*)\\??',\n",
    "     [\"Do you really think I don't {0}?\",\n",
    "      \"Perhaps eventually I will {0}.\",\n",
    "      \"Do you really want me to {0}?\"]],\n",
    " \n",
    "    [r'Why can\\'?t I ([^\\?]*)\\??',\n",
    "     [\"Do you think you should be able to {0}?\",\n",
    "      \"If you could {0}, what would you do?\",\n",
    "      \"I don't know -- why can't you {0}?\",\n",
    "      \"Have you really tried?\"]],\n",
    " \n",
    "    [r'I can\\'?t (.*)',\n",
    "     [\"How do you know you can't {0}?\",\n",
    "      \"Perhaps you could {0} if you tried.\",\n",
    "      \"What would it take for you to {0}?\"]],\n",
    " \n",
    "    [r'I am (.*)',\n",
    "     [\"Did you come to me because you are {0}?\",\n",
    "      \"How long have you been {0}?\",\n",
    "      \"How do you feel about being {0}?\"]],\n",
    " \n",
    "    [r'I\\'?m (.*)',\n",
    "     [\"How does being {0} make you feel?\",\n",
    "      \"Do you enjoy being {0}?\",\n",
    "      \"Why do you tell me you're {0}?\",\n",
    "      \"Why do you think you're {0}?\"]],\n",
    " \n",
    "    [r'Are you ([^\\?]*)\\??',\n",
    "     [\"Why does it matter whether I am {0}?\",\n",
    "      \"Would you prefer it if I were not {0}?\",\n",
    "      \"Perhaps you believe I am {0}.\",\n",
    "      \"I may be {0} -- what do you think?\"]],\n",
    " \n",
    "    [r'What (.*)',\n",
    "     [\"Why do you ask?\",\n",
    "      \"How would an answer to that help you?\",\n",
    "      \"What do you think?\"]],\n",
    " \n",
    "    [r'How (.*)',\n",
    "     [\"How do you suppose?\",\n",
    "      \"Perhaps you can answer your own question.\",\n",
    "      \"What is it you're really asking?\"]],\n",
    " \n",
    "    [r'Because (.*)',\n",
    "     [\"Is that the real reason?\",\n",
    "      \"What other reasons come to mind?\",\n",
    "      \"Does that reason apply to anything else?\",\n",
    "      \"If {0}, what else must be true?\"]],\n",
    " \n",
    "    [r'(.*) sorry (.*)',\n",
    "     [\"There are many times when no apology is needed.\",\n",
    "      \"What feelings do you have when you apologize?\"]],\n",
    " \n",
    "    [r'Hello(.*)',\n",
    "     [\"Hello... I'm glad you could drop by today.\",\n",
    "      \"Hi there... how are you today?\",\n",
    "      \"Hello, how are you feeling today?\"]],\n",
    " \n",
    "    [r'I think (.*)',\n",
    "     [\"Do you doubt {0}?\",\n",
    "      \"Do you really think so?\",\n",
    "      \"But you're not sure {0}?\"]],\n",
    " \n",
    "    [r'(.*) friend (.*)',\n",
    "     [\"Tell me more about your friends.\",\n",
    "      \"When you think of a friend, what comes to mind?\",\n",
    "      \"Why don't you tell me about a childhood friend?\"]],\n",
    " \n",
    "    [r'Yes',\n",
    "     [\"You seem quite sure.\",\n",
    "      \"OK, but can you elaborate a bit?\"]],\n",
    " \n",
    "    [r'(.*) computer(.*)',\n",
    "     [\"Are you really talking about me?\",\n",
    "      \"Does it seem strange to talk to a computer?\",\n",
    "      \"How do computers make you feel?\",\n",
    "      \"Do you feel threatened by computers?\"]],\n",
    " \n",
    "    [r'Is it (.*)',\n",
    "     [\"Do you think it is {0}?\",\n",
    "      \"Perhaps it's {0} -- what do you think?\",\n",
    "      \"If it were {0}, what would you do?\",\n",
    "      \"It could well be that {0}.\"]],\n",
    " \n",
    "    [r'It is (.*)',\n",
    "     [\"You seem very certain.\",\n",
    "      \"If I told you that it probably isn't {0}, what would you feel?\"]],\n",
    " \n",
    "    [r'Can you ([^\\?]*)\\??',\n",
    "     [\"What makes you think I can't {0}?\",\n",
    "      \"If I could {0}, then what?\",\n",
    "      \"Why do you ask if I can {0}?\"]],\n",
    " \n",
    "    [r'Can I ([^\\?]*)\\??',\n",
    "     [\"Perhaps you don't want to {0}.\",\n",
    "      \"Do you want to be able to {0}?\",\n",
    "      \"If you could {0}, would you?\"]],\n",
    " \n",
    "    [r'You are (.*)',\n",
    "     [\"Why do you think I am {0}?\",\n",
    "      \"Does it please you to think that I'm {0}?\",\n",
    "      \"Perhaps you would like me to be {0}.\",\n",
    "      \"Perhaps you're really talking about yourself?\"]],\n",
    " \n",
    "    [r'You\\'?re (.*)',\n",
    "     [\"Why do you say I am {0}?\",\n",
    "      \"Why do you think I am {0}?\",\n",
    "      \"Are we talking about you, or me?\"]],\n",
    " \n",
    "    [r'I don\\'?t (.*)',\n",
    "     [\"Don't you really {0}?\",\n",
    "      \"Why don't you {0}?\",\n",
    "      \"Do you want to {0}?\"]],\n",
    " \n",
    "    [r'I feel (.*)',\n",
    "     [\"Good, tell me more about these feelings.\",\n",
    "      \"Do you often feel {0}?\",\n",
    "      \"When do you usually feel {0}?\",\n",
    "      \"When you feel {0}, what do you do?\"]],\n",
    " \n",
    "    [r'I have (.*)',\n",
    "     [\"Why do you tell me that you've {0}?\",\n",
    "      \"Have you really {0}?\",\n",
    "      \"Now that you have {0}, what will you do next?\"]],\n",
    " \n",
    "    [r'I would (.*)',\n",
    "     [\"Could you explain why you would {0}?\",\n",
    "      \"Why would you {0}?\",\n",
    "      \"Who else knows that you would {0}?\"]],\n",
    " \n",
    "    [r'Is there (.*)',\n",
    "     [\"Do you think there is {0}?\",\n",
    "      \"It's likely that there is {0}.\",\n",
    "      \"Would you like there to be {0}?\"]],\n",
    " \n",
    "    [r'My (.*)',\n",
    "     [\"I see, your {0}.\",\n",
    "      \"Why do you say that your {0}?\",\n",
    "      \"When your {0}, how do you feel?\"]],\n",
    " \n",
    "    [r'You (.*)',\n",
    "     [\"We should be discussing you, not me.\",\n",
    "      \"Why do you say that about me?\",\n",
    "      \"Why do you care whether I {0}?\"]],\n",
    " \n",
    "    [r'Why (.*)',\n",
    "     [\"Why don't you tell me the reason why {0}?\",\n",
    "      \"Why do you think {0}?\"]],\n",
    " \n",
    "    [r'I want (.*)',\n",
    "     [\"What would it mean to you if you got {0}?\",\n",
    "      \"Why do you want {0}?\",\n",
    "      \"What would you do if you got {0}?\",\n",
    "      \"If you got {0}, then what would you do?\"]],\n",
    " \n",
    "    [r'(.*) mother(.*)',\n",
    "     [\"Tell me more about your mother.\",\n",
    "      \"What was your relationship with your mother like?\",\n",
    "      \"How do you feel about your mother?\",\n",
    "      \"How does this relate to your feelings today?\",\n",
    "      \"Good family relations are important.\"]],\n",
    " \n",
    "    [r'(.*) father(.*)',\n",
    "     [\"Tell me more about your father.\",\n",
    "      \"How did your father make you feel?\",\n",
    "      \"How do you feel about your father?\",\n",
    "      \"Does your relationship with your father relate to your feelings today?\",\n",
    "      \"Do you have trouble showing affection with your family?\"]],\n",
    " \n",
    "    [r'(.*) child(.*)',\n",
    "     [\"Did you have close friends as a child?\",\n",
    "      \"What is your favorite childhood memory?\",\n",
    "      \"Do you remember any dreams or nightmares from childhood?\",\n",
    "      \"Did the other children sometimes tease you?\",\n",
    "      \"How do you think your childhood experiences relate to your feelings today?\"]],\n",
    " \n",
    "    [r'(.*)\\?',\n",
    "     [\"Why do you ask that?\",\n",
    "      \"Please consider whether you can answer your own question.\",\n",
    "      \"Perhaps the answer lies within yourself?\",\n",
    "      \"Why don't you tell me?\"]],\n",
    " \n",
    "    [r'quit',\n",
    "     [\"Thank you for talking with me.\",\n",
    "      \"Good-bye.\",\n",
    "      \"Thank you, that will be $150.  Have a good day!\"]],\n",
    " \n",
    "    [r'(.*)',\n",
    "     [\"Please tell me more.\",\n",
    "      \"Let's change focus a bit... Tell me about your family.\",\n",
    "      \"Can you elaborate on that?\",\n",
    "      \"Why do you say that {0}?\",\n",
    "      \"I see.\",\n",
    "      \"Very interesting.\",\n",
    "      \"{0}.\",\n",
    "      \"I see.  And what does that tell you?\",\n",
    "      \"How does that make you feel?\",\n",
    "      \"How do you feel when you say that?\"]]\n",
    "]\n",
    " \n",
    " \n",
    "def reflect(fragment):\n",
    "    \n",
    "    # Turn a string into a series of words\n",
    "    tokens = fragment.lower().split()\n",
    "    \n",
    "    # for each word...\n",
    "    for i in range(len(tokens)):\n",
    "        token = tokens[i]\n",
    "    \n",
    "        # see if the word is in the \"reflections\" list and if it\n",
    "        # is, replace it with its reflection (you -> me, say)\n",
    "        if token in reflections:\n",
    "            tokens[i] = reflections[token]\n",
    "            \n",
    "    return ' '.join(tokens)\n",
    " \n",
    " \n",
    "def respond(statement):\n",
    "    \n",
    "    # run through all the actions\n",
    "    for j in range(len(actions)):\n",
    "    \n",
    "        # for each one, see if it matches the statment that was typed\n",
    "        pattern = actions[j][0] \n",
    "        responses = actions[j][1]\n",
    "        found = match(pattern, statement.rstrip(\".!\"),IGNORECASE)\n",
    "        \n",
    "        if found:\n",
    "        \n",
    "            # for the first match, select a response at random and insert\n",
    "            # the text from the statement into ELIZA's response\n",
    "            response = choice(responses)\n",
    "            return response.format(*[reflect(g) for g in found.groups()])\n",
    " \n",
    " \n",
    "def eliza():\n",
    "    # a friendly welcome\n",
    "    print(\"Hello. How are you feeling today?\")\n",
    " \n",
    "    # talk forever...\n",
    "    while True:\n",
    "        \n",
    "        # collect a statement and respond, stop the conversation on 'quit'\n",
    "        statement = input(\"> \")\n",
    "        print(respond(statement))\n",
    " \n",
    "        if statement == \"quit\":\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some constructions here you haven't seen. The `def ... :` is a way to create new functions. That is, you can build your own operations that take data in, operate on it, and return in some way. \n",
    "\n",
    "The final function eliza(), for example, drops you into a loop (a \"while\" loop that you \"break\" out of by typing \"quit\". The only other new thing here is that the notebook has a funciton \"raw_input\" that lets your reader type things and gives you access to their musings. Play with ELIZA a little. What do you think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eliza()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we turn you lose, let's examine the code a little. The reflect() function turns and \"I\" into a \"you\", allowing the program to turn a user's statement \"Because I love apples\" around into the question \"If you love apples, what else must be true?\" Here is reflect() working on single phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reflect(\"I am troubled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reflect(\"your analysis is wrong\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's look at the respond() function a little more closely. There are some new code constructions here. Here is respond() in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "respond(\"I am doing fine.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we take the same function but add a number of print statements to see what it's doing. The new function is called irespond() instead, to avoid confusion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def irespond(statement):\n",
    "    \n",
    "    # run through all the actions\n",
    "    for j in range(len(actions)):\n",
    "        \n",
    "        # for each one, see if it matches the statment that was typed\n",
    "        pattern = actions[j][0] \n",
    "        responses = actions[j][1]\n",
    "        found = match(pattern, statement.rstrip(\".!\"),IGNORECASE)\n",
    "        \n",
    "        if found:\n",
    "            \n",
    "            # for the first match, select a response at random and insert\n",
    "            # the text from the statement into ELIZA's response\n",
    "            \n",
    "            print \"Found pattern:\"\n",
    "            print pattern\n",
    "            print \"--\"*5\n",
    "            print \"Choosing between responses:\"\n",
    "            pprint(responses)\n",
    "            \n",
    "            response = choice(responses)            \n",
    "\n",
    "            print \"--\"*5\n",
    "            print \"The matched groups:\"\n",
    "            pprint([reflect(g) for g in found.groups()])\n",
    "            print \"--\"*5\n",
    "            \n",
    "            print \"ELIZA's response:\"\n",
    "            print response.format(*[reflect(g) for g in found.groups()])\n",
    "            print \"--\"*5\n",
    "            \n",
    "            return           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "irespond(\"My dog.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The responses have references that look like \"{0}\" and \"{1}\" and so on. Given a string with these special character strings, the method format() will substitute its first argument for \"{0}\", its second for \"{1}\" and so on. Here we make two substitutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"Not everything is {0} in words, only {1}\".format(\"sayable\",\"the living truth.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only other magic is the \"\\*\" inside the format() call in irespond() and respond(). What the star notation does is take a list and make it like each element is another argument for the function. So the list below has two elements, two strings, and the star make the call below just like the one above. The first element of the list is the first argument to format() and the second is the second argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"Not everything is {0} in words, only {1}\".format(*[\"sayable\",\"the living truth.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do this because the match() command returns a list of the groups identified in the regular expression -- the items marked out with parenthese. So above, the word \"dog\" is the only match and the groups() method returns a list with just one item. format() then takes that item and plops it into the response string, replacing \"{0}\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "irespond(\"do you think my mother would approve?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "irespond(\"I'm sad.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your turn! Start by copying and adapting the ELIZA code to fix up where it seems to get stuck, conversationally. When you are ready, start on your own bot. The more rules you rewrite the better. What are you going to talk about? What are you going to ground your conversation in? Maybe we ground it in Trump commentary (unless you're exhausted -- I'll understand)? [Here](https://www.nytimes.com/2016/11/18/technology/automated-pro-trump-bots-overwhelmed-pro-clinton-messages-researchers-say.html?_r=0) is a great article on simple political chat bots and another one [here](https://www.askhillaryanddonald.com/assets/Sample_Questions.pdf)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
